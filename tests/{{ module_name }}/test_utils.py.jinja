"""Tests for the utils module."""

from pathlib import Path
from typing import Dict, List, Any
import pytest
import json
import tempfile

from {{ module_name }}.utils import (
    validate_input,
    read_config_file,
    safe_divide,
    filter_and_sort,
    setup_logging
)


class TestValidateInput:
    """Test class for validate_input function."""
    
    def test_validate_input_correct_type(self) -> None:
        """Test validation with correct type."""
        assert validate_input("test", str) is True
        assert validate_input(42, int) is True
        assert validate_input([1, 2, 3], list) is True
        assert validate_input({"key": "value"}, dict) is True
    
    def test_validate_input_incorrect_type(self) -> None:
        """Test validation with incorrect type."""
        assert validate_input("test", int) is False
        assert validate_input(42, str) is False
        assert validate_input([1, 2, 3], dict) is False
        assert validate_input({"key": "value"}, list) is False
    
    def test_validate_input_none_not_allowed(self) -> None:
        """Test validation with None when not allowed."""
        assert validate_input(None, str) is False
        assert validate_input(None, int) is False
    
    def test_validate_input_none_allowed(self) -> None:
        """Test validation with None when allowed."""
        assert validate_input(None, str, allow_none=True) is True
        assert validate_input(None, int, allow_none=True) is True
        assert validate_input("test", str, allow_none=True) is True


class TestReadConfigFile:
    """Test class for read_config_file function."""
    
    def test_read_json_config(self, temp_config_file: Path) -> None:
        """Test reading JSON configuration file."""
        config = read_config_file(temp_config_file)
        
        assert isinstance(config, dict)
        assert config["name"] == "{{ project_name }}"
        assert config["version"] == "1.0.0"
        assert config["environment"] == "test"
    
    def test_read_keyvalue_config(self, temp_keyvalue_file: Path) -> None:
        """Test reading key=value configuration file."""
        config = read_config_file(temp_keyvalue_file)
        
        assert isinstance(config, dict)
        assert config["name"] == "{{ project_name }}"
        assert config["version"] == "1.0.0"
        assert config["environment"] == "test"
        assert config["debug"] == "true"
    
    def test_read_nonexistent_file(self) -> None:
        """Test reading a file that doesn't exist."""
        with pytest.raises(FileNotFoundError):
            read_config_file("nonexistent_file.json")
    
    def test_read_invalid_config_file(self) -> None:
        """Test reading an invalid configuration file."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.conf', delete=False) as f:
            f.write("invalid content without proper format")
            temp_path = Path(f.name)
        
        try:
            with pytest.raises(ValueError):
                read_config_file(temp_path)
        finally:
            temp_path.unlink()
    
    def test_read_empty_file(self) -> None:
        """Test reading an empty configuration file."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.conf', delete=False) as f:
            f.write("")
            temp_path = Path(f.name)
        
        try:
            with pytest.raises(ValueError):
                read_config_file(temp_path)
        finally:
            temp_path.unlink()


class TestSafeDivide:
    """Test class for safe_divide function."""
    
    def test_safe_divide_normal(self) -> None:
        """Test normal division."""
        assert safe_divide(10.0, 2.0) == 5.0
        assert safe_divide(7.5, 2.5) == 3.0
        assert safe_divide(-10.0, 2.0) == -5.0
    
    def test_safe_divide_by_zero_default(self) -> None:
        """Test division by zero with default return value."""
        assert safe_divide(10.0, 0.0) == 0.0
        assert safe_divide(-5.0, 0.0) == 0.0
    
    def test_safe_divide_by_zero_custom_default(self) -> None:
        """Test division by zero with custom default value."""
        assert safe_divide(10.0, 0.0, -1.0) == -1.0
        assert safe_divide(5.0, 0.0, 999.0) == 999.0
    
    def test_safe_divide_edge_cases(self) -> None:
        """Test edge cases for safe division."""
        assert safe_divide(0.0, 5.0) == 0.0
        assert safe_divide(0.0, 0.0) == 0.0


class TestFilterAndSort:
    """Test class for filter_and_sort function."""
    
    def test_filter_and_sort_default(self, sample_data: List[str]) -> None:
        """Test with default parameters (filter and sort)."""
        result = filter_and_sort(sample_data)
        
        # Should filter empty strings
        assert "" not in result
        
        # Should be sorted
        assert result == sorted(result)
        
        # Should contain expected items (stripped)
        assert "hello world" in result
        assert "python testing" in result
        assert "{{ package_name }}" in result
        assert "unit tests" in result
    
    def test_filter_only(self, sample_data: List[str]) -> None:
        """Test filtering without sorting."""
        result = filter_and_sort(sample_data, filter_empty=True, sort_items=False)
        
        # Should filter empty strings
        assert "" not in result
        
        # Should maintain relative order (not sorted)
        expected_order = ["hello world", "python testing", "{{ package_name }}", "unit tests"]
        assert result == expected_order
    
    def test_sort_only(self) -> None:
        """Test sorting without filtering."""
        data = ["zebra", "", "alpha", "  ", "beta"]
        result = filter_and_sort(data, filter_empty=False, sort_items=True)
        
        # Should keep empty strings
        assert "" in result
        assert "  " in result
        
        # Should be sorted
        assert result == sorted(result)
    
    def test_no_filter_no_sort(self, sample_data: List[str]) -> None:
        """Test without filtering or sorting."""
        result = filter_and_sort(sample_data, filter_empty=False, sort_items=False)
        
        # Should be identical to input (but stripped)
        expected = [item.strip() for item in sample_data]
        assert result == expected
    
    def test_filter_and_sort_empty_list(self) -> None:
        """Test with empty input list."""
        result = filter_and_sort([])
        assert result == []
    
    def test_filter_and_sort_whitespace_only(self) -> None:
        """Test with list containing only whitespace."""
        data = ["  ", "\t", "\n", "   \t\n   "]
        result = filter_and_sort(data)
        assert result == []


class TestSetupLogging:
    """Test class for setup_logging function."""
    
    def test_setup_logging_default(self) -> None:
        """Test logging setup with default parameters."""
        # Should not raise an exception
        try:
            setup_logging()
        except Exception as e:
            pytest.fail(f"setup_logging() raised {type(e).__name__}: {e}")
    
    def test_setup_logging_custom_level(self) -> None:
        """Test logging setup with custom level."""
        # Should not raise an exception
        try:
            setup_logging(level="DEBUG")
            setup_logging(level="WARNING")
            setup_logging(level="ERROR")
        except Exception as e:
            pytest.fail(f"setup_logging() raised {type(e).__name__}: {e}")
    
    def test_setup_logging_custom_format(self) -> None:
        """Test logging setup with custom format."""
        custom_format = "%(levelname)s: %(message)s"
        
        # Should not raise an exception
        try:
            setup_logging(format_string=custom_format)
        except Exception as e:
            pytest.fail(f"setup_logging() raised {type(e).__name__}: {e}")


# Parametrized tests
@pytest.mark.parametrize("a,b,expected", [
    (10.0, 2.0, 5.0),
    (15.0, 3.0, 5.0),
    (-10.0, 2.0, -5.0),
    (7.5, 1.5, 5.0),
])
def test_safe_divide_parametrized(a: float, b: float, expected: float) -> None:
    """Test safe_divide with various valid inputs."""
    result = safe_divide(a, b)
    assert abs(result - expected) < 1e-10  # Use small epsilon for float comparison


@pytest.mark.parametrize("data,filter_empty,sort_items,expected_count", [
    (["a", "b", "c"], True, True, 3),
    (["a", "", "b"], True, True, 2),
    (["a", "", "b"], False, True, 3),
    ([], True, True, 0),
    (["  ", "a", "  "], True, True, 1),
])
def test_filter_and_sort_parametrized(
    data: List[str], 
    filter_empty: bool, 
    sort_items: bool, 
    expected_count: int
) -> None:
    """Test filter_and_sort with various parameter combinations."""
    result = filter_and_sort(data, filter_empty=filter_empty, sort_items=sort_items)
    assert len(result) == expected_count


# Integration test
def test_utils_integration(temp_config_file: Path, sample_data: List[str]) -> None:
    """Test integration between multiple utility functions."""
    # Setup logging
    setup_logging(level="INFO")
    
    # Read configuration
    config = read_config_file(temp_config_file)
    assert validate_input(config, dict)
    
    # Process data
    processed_data = filter_and_sort(sample_data)
    assert validate_input(processed_data, list)
    
    # Safe calculations
    if len(processed_data) > 0:
        avg_length = safe_divide(
            sum(len(item) for item in processed_data),
            len(processed_data)
        )
        assert avg_length >= 0